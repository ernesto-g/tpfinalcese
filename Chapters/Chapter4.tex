% Chapter Template

\chapter{Ensayos y Resultados} % Main chapter title
En este capítulo se explica el desarrollo e implementación de tests unitarios y funcionales para el firmware y el software.

\label{Chapter4} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Tests unitarios para bibliotecas para el manejo de periféricos desde C}
\label{sec:testUnitariosC}

Para asegurar el correcto funcionamiento de las bibliotecas para el manejo de periféricos, se implementaron tests unitarios para la capa uPython HAL utilizando la técnica \textit{TAD}\footnote{TAD: Test-After Development. Técnica en la cual los tests se escriben luego de escribir el código.}. Mediante estos tests se probó el uso de las funciones de dicha capa cubriendo la complejidad ciclomática de cada una de ellas.

Teniendo como principal objetivo un consumo reducido de memoria de datos y de programa para la implementación de los tests (debido a que se ejecutan en la propia placa sin utilizar \textit{mocks}\footnote{Mock: Porción de código simple que simula otra porción de código más compleja.}), no se utilizó ninguna biblioteca existente, sino que se desarrolló una pequeña biblioteca mayormente compuesta por \textit{macros}\footnote{Macro: Fragmento de código con un nombre asociado.El precompilador reemplaza el nombre por el código.}, que permitió ejecutar los tests unitarios de una manera simple y controlada.

En el algotimo \ref{lst:utest} se muestra la función “utest\_startTest” la cual se encarga de ejecutar un test unitario. La misma recibe los argumentos que se detallan a continuación:

\begin{itemize}
	\item \textbf{fncTest}: una función donde se escribirá el test unitario.
	\item \textbf{fncBefore}: una función que en el caso de existir, se ejecutará antes de fncTest (puede utilizarse para inicializaciones antes de la ejecución del test).
	\item \textbf{testName}: un texto con el nombre del test, el cual se imprime antes de ejecutar las funciones (línea 8).	
\end{itemize}
	
El control de errores se observa en la línea 7 en donde se pone a cero la variable global “utest\_flagTestError”, luego de la ejecución de las funciones pasadas como argumento, en la línea 13 se evalúa el estado de dicha variable, la cual se pudo cargar con el valor 1 en la función del test si hubo un error. En dicho caso se imprime un mensaje de error (línea 15) indicando mediante otras variables globales el nombre del archivo y el número de línea donde se produjo el error en el test.

\begin{lstlisting}[label={lst:utest},caption=Función que ejecuta un test unitario incluida en el archivo utest.c del firmware.]
void utest_startTest(void(*fncTest)(void),
                     void(*fncBefore)(void),
                     char* testName)
{
	if(fncTest!=0)
	{
		utest_flagTestError=0;
		utest_print1("TESTING:%s\r\n",testName);
		if(fncBefore!=0)
			fncBefore();
		utest_totalTestsCounter++;
		fncTest();
		if(utest_flagTestError==1)
		{
			utest_print2("TEST FAILED. FILE:%s LINE:%d\r\n",
			              utest_fileTestError,utest_lineTestError);
		}
		else
		{
			utest_okTestsCounter++;
		}
	}
} 
\end{lstlisting}

Las variables globales mencionadas previamente se cargan en la ejecución de la función de test, para ello en el archivo utest.h del firmware, se definieron una serie de macros que permiten ejecutar las comparaciones de valores (\textit{asserts}\footnote{assert: En testing, es una función o macro que compara valores que deberían cumplirse, en caso contrario genera un error en el test.}) del test unitario.

En el algoritmo \ref{lst:utestmacro} se observa una de las macros definidas la cual es utilizada para comparar dos números enteros. En la línea 4 se realiza la comparación de los valores y en el caso de que no sean iguales se imprime un mensaje de error (línea 6) y se cargan las variables globales que son analizadas en la función “utest\_startTest”.

\begin{lstlisting}[label={lst:utestmacro},caption=Ejemplo de una macro assert incluida en el archivo utest.h del firmware.]

#define utest_assertEqualsInt(A,B)	
{ 
	if(A!=B)
	{ 
		utest_print2("assert equals failed '%d' != '%d'\r\n",A,B); 
		utest_flagTestError=1; 
		utest_lineTestError = __LINE__;  
		utest_fileTestError = __FILE__;
		return; 
	} 
}
\end{lstlisting}

En el algoritmo \ref{lst:testeeprom} puede apreciarse el uso de la macro “utest\_assertEqualsInt” la cual recibe el valor esperado (-1) y el valor devuelto por la función de la capa uPython HAL que escribe en la EEPROM. Esta función es uno de los tests unitarios escritos para el manejo de la EEPROM del microcontrolador. La macro realiza la comparación, y en caso de error, imprime el mensaje y carga las variables globales necesarias para que se puedan imprimir los datos del error. La sentencia “return” hace que se termine la ejecución de la función del test.

\begin{lstlisting}[label={lst:testeeprom},caption=Ejemplo de un test unitario para la EEPROM usando una dirección inválida.]
void testEEPROM2(void)
{
	int32_t r = mp_hal_writeByteEEPROM(0x8000,0x55); // invalid address
	utest_assertEqualsInt(-1,(int)r);
}
\end{lstlisting}

Para ejecutar la función “testEEPROM2” así como el resto de las funciones de test para todos los periféricos, se definió el archivo mainTest.c, en el cual se ejecutan las llamadas a la función “utest\_startTest” mencionada en el algoritmo \ref{lst:utest} y en donde se colocaron líneas de código como la que se observa en el algoritmo \ref{lst:testmain} en una función llamada “startTesting”. 

\begin{lstlisting}[label={lst:testmain},caption=Ejemplo de ejecución de funciones de test en archivo mainTest.c.]
	utest_startTest(testEEPROM1,0,"EEPROM: write/read byte Test");
	utest_startTest(testEEPROM2,0,"EEPROM: write invalid address Test");
	utest_startTest(testEEPROM3,0,"EEPROM: read invalid address Test");
\end{lstlisting}

Esta función “startTesting” se ejecuta en el main principal del firmware en el caso de que se compile indicando que se quieren ejecutar los tests (ver sección \ref{sec:testUnitariosPlaca}).

La estructura de archivos referidos a los tests se muestra en la figura \ref{fig:utestcarq}. Los archivos llamados testsXXX.c poseen las funciones de cada test unitario referido a cada periferico, las cuales utilizan las macros definidas en utest.h para realizar las comparaciones (asserts). Todos estos archivos se encuentran dentro de una carpeta llamada testing, y los mismos no se incluyen en el firmware excepto que se compile el mismo para ejecutar los tests.

\begin{figure}[ht]
  \centering
    \includegraphics[width=0.57\textwidth]{Figures/fig_utests_c}
  \caption{Estructura de archivos para la ejecución de tests unitarios de la capa uPython HAL.}
  \label{fig:utestcarq}
\end{figure}

%----------------------------------------------------------------------------------------------------------------------------------------------------

\section{Test unitarios para bibliotecas para el manejo de periféricos desde Python}
\label{sec:testUnitariosPython}

Para asegurar el correcto funcionamiento de las bibliotecas para el manejo de periféricos desde Python, se implementaron tests unitarios para todas las clases Python desarrolladas. Mediante estos tests se pretendió probar el uso de los métodos de dicha capa cubriendo la complejidad ciclomática de cada una de ellos.

Una vez más teniendo como principal objetivo un consumo reducido de memoria de datos y de programa para la implementación de los tests, no se utilizó ninguna biblioteca de tests unitarios para Python, sino que se escribió una que posea lo mínimo indispensable para la ejecución de los tests, en un módulo llamado unittest. 

Este módulo forma parte de las bibliotecas Python que pueden escribirse directamente en Python y no en C (bloque Frozen, ver apéndice \ref{AppendixB}), e incorporarse al firmware y al conjunto de módulos que el usuario puede utilizar para programar Python. El código Python escrito se transforma en un array de C y se incluye como parte del firmware en el momento de la compilación. Esto permite su posterior uso por el intérprete de Python.

En esta biblioteca se definió la clase TestCase, una parte de ella puede observarse en el algoritmo \ref{lst:testcase} en donde se muestra la definición de la clase y de los métodos:

\begin{itemize}
	\item \textbf{setUp}: método que se ejecutará antes del método de test.
	\item \textbf{tearDown}: método que se ejecutará despues del método de test.
	\item \textbf{assertEqual}: método assert encargado de comparar dos valores por igual. En el caso de no ser iguales, se lanza una excepción que será capturada por el método que ejecuta los tests.
\end{itemize}

\begin{lstlisting}[label={lst:testcase},caption=Clase TestCase utilizada para crear tests unitarios para Python., language={python}]
class TestCase (object):
    testCounter=0
    testOKCounter=0

    def setUp(self):
        pass
    
    def tearDown(self):
        pass

    def assertEqual(self,v1,v2,m):
        if v1 != v2:
            raise TestException(m)
\end{lstlisting}

La clase posee muchos más métodos assertXXX para poder comparar todo tipo de datos.

Para escribir un test, se debe crear una clase que herede de TestCase, en donde se deben definir los métodos test\_X siendo X un número comenzando de 1.

En el algoritmo \ref{lst:testpyeeprom} se muestra un ejemplo de una clase “TestEEPROM” la cual hereda de “TestCase” y posee definido los métodos de los tests, en el ejemplo se muestra solo el método “test\_1”, el cual hace uso del método “assertEqual”, esto es posible debido a que la clase hereda de “TestCase”.

\begin{lstlisting}[label={lst:testpyeeprom},caption=Clase que hereda de TestCase donde se definen los métodos de test para la EEPROM., language={python}]
from unittest import TestCase
import pyb
  
class TestEEPROM (TestCase):

    def test_1(self):
        eeprom = pyb.EEPROM()
        eeprom.write_byte(0x0000,0x55)
        val = eeprom.read_byte(0x0000)
        self.assertEqual(0x55,val,"EEPROM addr 0x0000")       
\end{lstlisting}

En la figura \ref{fig:unittestpythonclassd} el diagrama de clases del módulo unittest muestra la clase “TestCase” con todos sus métodos “assertXXX” y cómo las clases donde se definen los test (“TestXXX”) deben heredar de “TestCase” e implementar los métodos “test\_X” como lo hace “TestEEPROM”.

\begin{figure}[ht]
  \centering
    \includegraphics[width=0.8\textwidth]{Figures/fig_unittest_class_diagram}
  \caption{Diagrama de clases del módulo unittest.}
  \label{fig:unittestpythonclassd}
\end{figure}

Para ejecutar los tests, se utiliza el método estático “run()”, el cual debe recibir un objeto creado a partir de una clase que herede de “TestCase” y que posea los métodos “test\_X”.

El método estático “run()”, encargado de ejecutar los tests unitarios, puede apreciarse en el algoritmo \ref{lst:utestsrun}, en donde se observa que el mismo recibe un objeto y mediante el método “hasattr” (línea 6) se consulta si el mismo posee el método llamado “nName” (variable que contiene un string con el formato “test\_X”). En el caso de que el objeto posea el método, se obtiene dicho método mediante “getattr” (línea 7) y dentro de un bloque \textit{try-except}\footnote{try-except: Bloque de código Python que permite capturar una excepción.} se procede a la ejecución del mismo (línea 12) ejecutando previamente el método “setUp” y posteriormente el método “tearDown”.

\begin{lstlisting}[label={lst:utestsrun},caption=Método que ejecuta los métodos de test en la biblioteca unittest.py implementada., language={python}]
@staticmethod
def run(o):
		i=1
		while True:
				mName = "test_"+str(i)
				if hasattr(o,mName):
						m = getattr(o,mName)
						print("Testing "+mName+" ... ")
						TestCase.testCounter+=1
						try:
								o.setUp()
								m()
								o.tearDown()
								TestCase.testOKCounter+=1
						except Exception as e:
								print("ASSERT ERROR:"+str(e))
				else:
						break
				i+=1
\end{lstlisting}

Si dentro de la ejecución del método “m()” un assert falla, se lanzará una excepción, y el bloque “try-except” la capturará y se imprimirá el mensaje de error.

Las clases Python que heredan de “TestCase” para cada periférico se listan a continuación:

\begin{itemize}
	\item \textbf{TestLeds}
	\item \textbf{TestSwitches}
	\item \textbf{TestUart}
	\item \textbf{TestEEPROM}
	\item \textbf{TestDAC}
	\item \textbf{TestADC}
	\item \textbf{TestGPIO}
	\item \textbf{TestRS485}	
	\item \textbf{TestTimers}
\end{itemize}

En el algoritmo \ref{lst:maintestpython} se observa la definición de la clase “MainTest” la cual posee un método “run” y dentro del mismo se colocaron todas las llamadas al método estático “run” de la clase “TestCase”, pasando como argumento un objeto de cada una de las clases que hereda de “TestCase”.

\begin{lstlisting}[label={lst:maintestpython},caption=Clase MainTest desde donde se ejecutan todos los tests Python., language={python}]
class MainTest (object):
    def run(self):
        print("Running python tests")

        print("LEDs Tests")
        TestCase.run(TestLeds())
        print("____________________")

        print("Switches Tests")
        TestCase.run(TestSwitches())
        print("____________________")
				#...
\end{lstlisting}
 
%--------------------------------------------------------------------------------------------------------------------------------------------------

\section{Ejecución de los tests sobre la placa}
\label{sec:testUnitariosPlaca}

Para llevar a cabo la ejecución de los tests unitarios sobre la placa, se modificó el archivo Makefile agregando la regla "`test"'. Como se indica en el algoritmo \ref{lst:makefile} la regla test incluye en la compilación la definición de la macro TESTING (línea 1) y la definición de una variable de entorno MP\_INCLUDE\_TESTS (línea 2).

\begin{lstlisting}[label={lst:makefile},caption=Regla test en Makefile.]
test: CFLAGS += -DTESTING
test: export MP_INCLUDE_TESTS = true
test: all 
\end{lstlisting}

La definción TESTING se utiliza en el archivo main.c como se observa en el algoritmo \ref{lst:mainc} para incluir todos los archivos mencionados en las secciones anteriores, e incluir las llamadas a la función “startTesting” (línea 10), para ejecutar los tests unitarios para la capa uPython HAL, y la función “do\_str” (línea 12) para ejecutar una porción de código Python que crea un objeto MainTest y ejecuta el método “run” de dicha clase, iniciando así la ejecución de todos los test unitarios escritos en Python.

\begin{lstlisting}[label={lst:mainc},caption=Inclusión de los archivos de test en el main.]
#ifdef TESTING
    #include "testing/mainTest.c"
    #include "testing/pythonTest.c" // do_str function
#endif
//...
int main(int argc, char **argv) {
	//...
	#ifdef TESTING
			// Run C tests
			startTesting();
			// Run Python tests
			do_str("import testing_MainTest\r\n
			        m=testing_MainTest.MainTest()\r\n
							m.run()\r\n\0",MP_PARSE_FILE_INPUT);
			return 0;
	#endif
	//...
}
\end{lstlisting}

Para compilar el firmware habilitando la ejecución de los tests, simplemente se ejecuta:

\textbf{{\fontsize{16}{16}\selectfont \textgreater\textgreater}} \texttt{make test}\\

La variable de entorno “MP\_INCLUDE\_TESTS” sirve para que el script que genera código C a partir del código Python escrito como Frozen (ver apéndice \ref{AppendixB}), incluya las clases de test escritas en Python, de lo contrario estas clases no se incluyen en el firmware, para minimizar el tamaño de la memoria requerida. Esto es posible ya que los archivos de test se encuentran dentro de una carpeta “testing” dentro de la carpeta “frozen”, la cual es omitida segúl el estado de la variable.

\subsection{Requerimientos para la ejecución de los tests.}
\label{sec:requerimientosEjecucionTests}

Los tests desarrollados no fueron pensados para probar el hardware sino el firmware, esto quiere decir que es un requerimiento necesario que los periféricos del microcontrolador funcionen correctamente en su interfaz física (pines, señales eléctricas, etc.)
Los tests unitarios que tienen relación con el hardware pueden dividirse en tres tipos \cite{tdd} detallados a continuación:

\begin{itemize}
	\item \textbf{Tests de hardware automáticos}: los tests se ejecutan de forma automática desde su inicio hasta su fin y arrojan los resultados obtenidos.
	\item \textbf{Tests de hardware automáticos parciales}: requieren intervencion manual durante el proceso.
	\item \textbf{Tests de hardware automáticos con instrumentación externa}: requieren un instrumento externo que se conecte al hardware a testear.
\end{itemize}

Los test desarrollados en este trabajo pueden catalogarse como parciales y con instrumentación externa, ya que se requiere intervención de una persona en ciertas etapas (por ejemplo para presionar un pulsador) y también se requiere la conexión de un dispositivo para recibir y reenviar las tramas RS-485 generadas en los tests.

En la tabla \ref{tab:hardreq} se detallan las conexiones de hardware requeridas para la ejecución de los tests, las comunicaciones seriales (las dos UARTs) requieren que se reciba lo mismo que se transmite, por lo que en el caso de la UART a nivel 3.3V se soluciona conectando ambos pines entre sí, pero en el caso de la interfaz RS-485 se requiere conectar el bus a un dispositivo externo (una PC con entrada RS-485 por ejemplo) que reciba y envíe lo recibido.
Para probar las GPIOs tanto en su configuración como entradas así como su configuración como salidas, el problema se resuelve conectando dos GPIOs entre sí. Se recuerda que el propósito del test no es probar el funcionamiento del hardware, por lo que con solo utilizar dos pines se pueden completar los tests requeridos. Por último se conectan las entradas analógicas a un valor de 0V.

\begin{table}[h]
	\centering
	\caption[Conexiones de hardware requeridas para ejecutar los tests]{Conexiones de hardware requeridas para ejecutar los tests.}
	\begin{tabular}{l c}    
		\toprule
		\textbf{PIN} 	 	& \textbf{Conectar a}   									\\
		\midrule
		232\_RX	 				& 232\_TX (con una R de 100ohm en serie)		\\	
		GPIO8	 					& GPIO7 (con una R de 100ohm en serie)		\\		
		CH1	 						& GNDA																		\\		
		CH2	 						& GNDA																		\\		
		CH3	 						& GNDA																		\\		
		RS485						& Terminal con eco.9600-8N1								\\
		\bottomrule
		\hline
	\end{tabular}
	\label{tab:hardreq}
\end{table}

Se realizazon 58 tests para la capa uPython HAL y 69 tests para la capa de Python que utiliza el usuario.

\section{Tests Unitarios para ventanas que componen el IDE}
\label{sec:testUnitariosIDE}

Para la creación de tests unitarios que comprueben el funcionamiento de las ventanas del IDE y el proceso de grabación del código Python en la placa, se utilizó la biblioteca standard de Python llamada unittest la cual posee la clase TestCase. Como el IDE se ejecuta en una PC, no se utilizó la versión de unittest desarrollada para uPython (ver sección \ref{sec:testUnitariosPython}) sino que se optó por el uso de la original.

En la figura \ref{fig:unittestide} puede observarse el diagrama de clases que involucra a la clase TestCase como clase padre de todas las clases de test que se implementaron.A diferencia de la biblioteca unittest para uPython, aquí los nombres de los métodos deben comenzar con “test\_”.

\begin{figure}[h]
  \centering
    \includegraphics[width=0.9\textwidth]{Figures/fig_unittest_ide}
  \caption{Diagrama de clases de tests unitarios para el IDE}
  \label{fig:unittestide}
\end{figure}

A continuación se detallan los test implementados:

\begin{enumerate}
	\item  \textbf{EditorTest}: se chequean las funcionalidades básicas de la ventana del IDE (abrir y guardar un archivo, etc.).
	\item  \textbf{SnippetsWindowTest y SnippetsParserTest}: comprueban la correcta lectura del archivo XML con las porciones de código de ejemplo y su inserción en el código.
	\item  \textbf{ConfigWindowTest y ConfigManagerTest}: comprueban el correcto manejo de los datos de configuración (el nombre del puerto serial seleccionado).
	\item  \textbf{ConsoleWindowTest}: aquí se definen los tests para las operaciones de texto que realiza la consola, como agregar y quitar un texto de la misma.
	\item  \textbf{LoadingWindowTest}: comprueba el envío del archivo con el código Python.
\end{enumerate}

Si bien la mayoría de los test se realizaron para comprobar el correcto funcionamiento de las ventanas, también existen algunos que comprueban el funcionamiento de clases de bajo nivel, como por ejemplo, la encargada de leer el archivo XML con los snippets, o la encargada de leer y guardar la configuración. Al ejecutar los tests se crean múltiples instancias de las ventanas del IDE y el resultado de los tests se emite por la consola.



\section{Tests funcionales}
\label{sec:testFuncionales}

Para comprobar la integración de todas las funcionalidades testeadas en forma aislada mediante los tests unitarios anteriormente descriptos, se agregaron una serie de tests funcionales. Los tests funcionales desarrollados pueden agruparse en dos categorías: aquellos que permiten comprobar el correcto funcionamiento de las clases Python que utilizará el usuario para desarrollar sus aplicaciones sobre la plataforma EDU-CIAA-NXP, y los destinados a chequear el correcto funcionamiento entre las distintas ventanas del IDE.

Para escribir estos tests, primero se listaron los requerimientos asignándoles un nombre con la forma R-XX, por ejemplo R-01 o R-02, luego se escribieron los tests funcionales, cada uno cubrió al menos un requerimiento, y se nombraron con la forma TF-XX por ejemplo TF-01 o TF-02. Cada test consiste en una lista de pre-requisitos y una serie de pasos que el usuario debe seguir y que le indican qué hacer, y cual es el resultado esperado para cada paso. Al final del test se aclara qué requisitos cubre el test realizado.

Por último se elaboró la matriz de trazabilidad, la cual consiste en una tabla con los nombres de los requerimientos en las columnas y los nombres de los tests en las filas y en donde se indica qué test cubre qué requerimiento mediante una X.


\subsection{Tests funcionales para el IDE}

Para el desarrollo de los tests funcionales del IDE se listaron un total de ocho requerimientos, los cuales dieron origen a siete tests funcionales. Como ejemplo se expone a continuación el test TF-01:

\textbf{Test funcional TF-01: Ventana de Configuración del puerto serie.}

Pre-condiciones:
\begin{itemize}
	\item Existe una placa EDU-CIAA-NXP conectada a la PC.
	\item El IDE se encuentra instalado en la computadora.
\end{itemize}

Pasos:
\begin{enumerate}
	\item Abrir el IDE. Resultado: deberá aparecer un splash y luego la ventana del editor.
	\item Seleccionar el menú “EDU-CIAA” -> Configuration. Resultado: se lanzará una nueva ventana con la configuración del puerto serie.
	\item Seleccionar del combo el puerto serie correspondiente a la placa. Resultado: al desplegar el combo deberá aparecer al menos una opción.
	\item Presionar OK. Resultado: la ventana deberá cerrarse.
\end{enumerate}
	
Requerimiento testeado:R-07


\subsection{Tests funcionales para clases Python de manejo de periféricos}

En el caso particular de los tests funcionales para las clases Python de manejo de periféricos, se listaron ocho requerimientos, que dieron origen a 8 tests funcionales, un ejemplo de los mismos es el test TF-08:

\textbf{Test Funcional T-08. Módulo de Python pyb.EEPROM.}

Pasos:
\begin{enumerate}
	\item Abrir el IDE.
	\item Conectar la EDU-CIAA-NXP y configurar el Puerto Serie en el IDE.
	\item Escribir un programa que cree un objeto EEPROM.
	\item Escribir en la dirección 0x0000 el valor 0x27.
	\item Ejecutar el programa para que se escriba el valor en la EEPROM.
	\item Comentar la línea de la escritura.
	\item Leer el valor en la dirección 0x0000 e imprimirlo en hexadecimal.
	\item Volver a ejecutar el programa, debería aparecer el valor 0x27.
\end{enumerate}

Código a escribir:

\begin{verbatim}
import pyb
eeprom = pyb.EEPROM()
#eeprom.write_byte(0x0000,0x27)
val = eeprom.read_byte(0x0000)
print(hex(val))
\end{verbatim}

Requerimiento testeado:R-08


Mediante el desarrollo de estos tests, se logró comprobar el correcto funcionamiento de la herramienta presentada en este trabajo en su totalidad, incluyendo todas las partes de la misma. 

Si bien la implementación de test unitarios y funcionales no garantiza que el proyecto se encuentre completamente libre de errores, sí demuestra que el desarrollo del presente trabajo final se ha llevado a cabo de manera ordenada, metódica, repetible y profesional.
